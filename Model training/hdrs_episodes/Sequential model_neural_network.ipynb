{"cells":[{"cell_type":"markdown","metadata":{"id":"lP6JLo1tGNBg"},"source":["# Artificial Neural Network"]},{"cell_type":"markdown","metadata":{"id":"1E0Q3aoKUCRX"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"gWZyYmS_UE_L"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxkJoQBkUIHC"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZaTwK7ojXr2F","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1658832758242,"user_tz":-330,"elapsed":34,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"ed64ad2e-0755-4ef6-ab10-7f7b115a8411"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"cKWAkFVGUU0Z"},"source":["### Importing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXUkhkMfU4wq"},"outputs":[],"source":["dataset = pd.read_csv('hdrs_episodes.csv')\n","X = dataset.iloc[:, 1:-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYP9cQTWbzuI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658832758245,"user_tz":-330,"elapsed":31,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"f1e6bc0f-be75-437e-9dc9-46ac5811f881"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0]\n"," [3 0 0 0 0 0 0 0 0 3 0 0 2 3 0 1 3 0 0 0]\n"," [2 1 0 0 2 0 0 0 0 0 1 0 1 0 2 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [2 2 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [2 1 0 0 0 0 0 0 0 2 0 1 1 0 0 0 0 0 0 0]\n"," [1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [1 0 0 2 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0 2 0 0 0]\n"," [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"," [2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"]}],"source":["print(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38vKGE6Nb2RR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658832758246,"user_tz":-330,"elapsed":29,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"8dd03b20-01cc-4aeb-8d5b-40371aec45f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["['N' 'N' 'M' 'M' 'N' 'N' 'N' 'N' 'D' 'D' 'D' 'N' 'N' 'N' 'N' 'N' 'D' 'N'\n"," 'M' 'D' 'N' 'M' 'D' 'D' 'M' 'N' 'N' 'M' 'D' 'N' 'N' 'N' 'N' 'D' 'N' 'D']\n"]}],"source":["print(y)"]},{"cell_type":"markdown","metadata":{"id":"N6bQ0UgSU-NJ"},"source":["### Encoding categorical data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxVKWXxLbczC"},"outputs":[],"source":["y= np.array(y.reshape(len(y),1))"]},{"cell_type":"markdown","metadata":{"id":"CUxGZezpbMcb"},"source":["One Hot Encoding the Y column"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AMXC8-KMVirw"},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])])\n","y = np.array(ct.fit_transform(y))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZcxwEon-b8nV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658832758247,"user_tz":-330,"elapsed":25,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"99b8ed43-007d-4191-9fa4-d08d6a2835c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]]\n"]}],"source":["print(y)"]},{"cell_type":"markdown","metadata":{"id":"vHol938cW8zd"},"source":["### Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z-TDt0Y_XEfc"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"]},{"cell_type":"markdown","metadata":{"id":"RE_FcHyfV3TQ"},"source":["### Feature Scaling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ViCrE00rV8Sk"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1OK_PznyHIHT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658832758248,"user_tz":-330,"elapsed":24,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"24747b39-a29a-4adc-f7e5-40c5faa9981a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.6882472  -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009  4.6306315  -0.19245009  2.76083723  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.          2.88675135 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.          2.88675135 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016  1.58113883 -0.2773501  -0.19245009\n","  -0.26211122  1.47709789  0.         -0.19245009  2.76993978  0.\n","   0.          0.        ]\n"," [ 0.6882472  -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.          2.88675135  1.58113883 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009  1.18321596  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009  2.76083723  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [ 0.6882472  -0.19245009  2.18426014 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501   5.19615242\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [ 1.97297531  5.19615242 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016  2.68793601 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553  3.60555128 -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016  0.47434165 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [ 0.6882472  -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016  0.47434165 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009  2.76083723  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [ 0.6882472  -0.19245009 -0.26211122  5.19615242 -0.39440532  0.\n","   0.          0.         -0.34641016  0.47434165  3.60555128 -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [ 0.6882472  -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016  0.47434165 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016  0.47434165 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [ 3.25770342 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016  2.68793601 -0.2773501  -0.19245009\n","   4.6306315   4.92365964  0.          5.19615242  4.29069103  0.\n","   0.          0.        ]\n"," [ 1.97297531 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","   2.18426014 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016 -0.63245553 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]\n"," [-0.59648091 -0.19245009 -0.26211122 -0.19245009 -0.39440532  0.\n","   0.          0.         -0.34641016  0.47434165 -0.2773501  -0.19245009\n","  -0.26211122 -0.24618298  0.         -0.19245009 -0.27156272  0.\n","   0.          0.        ]]\n"]}],"source":["print(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPAGk2yVRyPC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658832758248,"user_tz":-330,"elapsed":20,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"7ce01b30-1677-427c-b8d5-69a120c09489"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n"]}],"source":["print(y_train)"]},{"cell_type":"markdown","metadata":{"id":"-zfEzkRVXIwF"},"source":["## Part 2 - Building the ANN"]},{"cell_type":"markdown","metadata":{"id":"KvdeScabXtlB"},"source":["### Initializing the ANN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dtrScHxXQox"},"outputs":[],"source":["ann = tf.keras.models.Sequential()"]},{"cell_type":"markdown","metadata":{"id":"rP6urV6SX7kS"},"source":["### Adding the input layer and the first hidden layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bppGycBXYCQr"},"outputs":[],"source":["\n","ann.add(tf.keras.layers.Dense(units=128, activation='relu'))"]},{"cell_type":"markdown","metadata":{"id":"BELWAc_8YJze"},"source":["### Adding the second hidden layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YHcQAsy2oATR"},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=64, activation='relu'))\n","ann.add(tf.keras.layers.Dense(units=3, activation='relu'))\n"]},{"cell_type":"markdown","metadata":{"id":"OyNEe6RXYcU4"},"source":["### Adding the output layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cn3x41RBYfvY"},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=3, activation='softmax'))"]},{"cell_type":"markdown","metadata":{"id":"JT4u2S1_Y4WG"},"source":["## Part 3 - Training the ANN"]},{"cell_type":"markdown","metadata":{"id":"8GWlJChhY_ZI"},"source":["### Compiling the ANN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fG3RrwDXZEaS"},"outputs":[],"source":["ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"0QR_G5u7ZLSM"},"source":["### Training the ANN on the Training set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHZ-LKv_ZRb3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658832764562,"user_tz":-330,"elapsed":5759,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"75e1ded4-bb07-446e-9a39-99addc36ea5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","6/6 [==============================] - 1s 3ms/step - loss: 1.0885 - accuracy: 0.5000\n","Epoch 2/100\n","6/6 [==============================] - 0s 4ms/step - loss: 1.0178 - accuracy: 0.5714\n","Epoch 3/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.9624 - accuracy: 0.6786\n","Epoch 4/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.9027 - accuracy: 0.6786\n","Epoch 5/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.8534 - accuracy: 0.6786\n","Epoch 6/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.7931 - accuracy: 0.7143\n","Epoch 7/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.7572 - accuracy: 0.7143\n","Epoch 8/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.7209 - accuracy: 0.7143\n","Epoch 9/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.7143\n","Epoch 10/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.7500\n","Epoch 11/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7500\n","Epoch 12/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.7500\n","Epoch 13/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7500\n","Epoch 14/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7500\n","Epoch 15/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7500\n","Epoch 16/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7500\n","Epoch 17/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7500\n","Epoch 18/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7857\n","Epoch 19/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7857\n","Epoch 20/100\n","6/6 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7857\n","Epoch 21/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7857\n","Epoch 22/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7857\n","Epoch 23/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7857\n","Epoch 24/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7857\n","Epoch 25/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7857\n","Epoch 26/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.8571\n","Epoch 27/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8571\n","Epoch 28/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.8571\n","Epoch 29/100\n","6/6 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8571\n","Epoch 30/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8571\n","Epoch 31/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8571\n","Epoch 32/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.8571\n","Epoch 33/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8571\n","Epoch 34/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8571\n","Epoch 35/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8571\n","Epoch 36/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8571\n","Epoch 37/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8571\n","Epoch 38/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8571\n","Epoch 39/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8571\n","Epoch 40/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8571\n","Epoch 41/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8571\n","Epoch 42/100\n","6/6 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8571\n","Epoch 43/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8571\n","Epoch 44/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8571\n","Epoch 45/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8571\n","Epoch 46/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8571\n","Epoch 47/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8571\n","Epoch 48/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8571\n","Epoch 49/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8571\n","Epoch 50/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8571\n","Epoch 51/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8571\n","Epoch 52/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8571\n","Epoch 53/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8571\n","Epoch 54/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8571\n","Epoch 55/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8571\n","Epoch 56/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8571\n","Epoch 57/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8571\n","Epoch 58/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3714 - accuracy: 0.8571\n","Epoch 59/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8571\n","Epoch 60/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8571\n","Epoch 61/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8571\n","Epoch 62/100\n","6/6 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8571\n","Epoch 63/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8571\n","Epoch 64/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8571\n","Epoch 65/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8571\n","Epoch 66/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8571\n","Epoch 67/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8571\n","Epoch 68/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8571\n","Epoch 69/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8571\n","Epoch 70/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8571\n","Epoch 71/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8571\n","Epoch 72/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8571\n","Epoch 73/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8571\n","Epoch 74/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8571\n","Epoch 75/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8571\n","Epoch 76/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8571\n","Epoch 77/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8571\n","Epoch 78/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8571\n","Epoch 79/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8571\n","Epoch 80/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8571\n","Epoch 81/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8571\n","Epoch 82/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8571\n","Epoch 83/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8571\n","Epoch 84/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8571\n","Epoch 85/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8571\n","Epoch 86/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8571\n","Epoch 87/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8571\n","Epoch 88/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8571\n","Epoch 89/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8571\n","Epoch 90/100\n","6/6 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8571\n","Epoch 91/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8571\n","Epoch 92/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8571\n","Epoch 93/100\n","6/6 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8571\n","Epoch 94/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8571\n","Epoch 95/100\n","6/6 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8571\n","Epoch 96/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8571\n","Epoch 97/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8571\n","Epoch 98/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8571\n","Epoch 99/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8571\n","Epoch 100/100\n","6/6 [==============================] - 0s 3ms/step - loss: 0.3389 - accuracy: 0.8571\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0654ff9150>"]},"metadata":{},"execution_count":21}],"source":["ann.fit(X_train, y_train, batch_size = 5, epochs = 100)"]},{"cell_type":"markdown","metadata":{"id":"tJj5k2MxZga3"},"source":["## Part 4 - Making the predictions and evaluating the model"]},{"cell_type":"markdown","metadata":{"id":"u7yx47jPZt11"},"source":["### Predicting the Test set results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIyEeQdRZwgs"},"outputs":[],"source":["ytest_pred = ann.predict(X_test)\n","ytrain_pred = ann.predict(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Up3Id9FamJCh"},"outputs":[],"source":["y_test_predRounded= []\n","y_test_predEncoded = []\n","ytrain_pred= []\n","ytrain_predRoundeded = []\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hn9vPnXaRRZE"},"outputs":[],"source":["def round(predicted,rounded):\n","  for i in range(len(predicted)):\n","    if predicted[i,0] >  predicted[i,1] and predicted[i,0] >  predicted[i,2]:\n","      rounded.append([1.,0.,0.])\n","    elif predicted[i,1] >  predicted[i,0] and predicted[i,1] >  predicted[i,2]:\n","      rounded.append([0.,1.,0.])\n","    elif predicted[i,2] >  predicted[i,0] and predicted[i,2] >  predicted[i,1]:\n","      rounded.append([0.,0.,1.])\n","    else:\n","      rounded.append([0.,0.,1.])\n","\n","def encode(predicted,encoded):\n","  for i in range(len(predicted)):\n","    if predicted[i,0] >  predicted[i,1] and predicted[i,0] >  predicted[i,2]:\n","      encoded.append(['D'])\n","    elif predicted[i,1] >  predicted[i,0] and predicted[i,1] >  predicted[i,2]:\n","      encoded.append(['M'])\n","    elif predicted[i,2] >  predicted[i,0] and predicted[i,2] >  predicted[i,1]:\n","      encoded.append(['N'])\n","    else:\n","      encoded.append(['N'])\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9-iXheDqeYQ"},"outputs":[],"source":["round(ytest_pred,y_test_predRounded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKiFnOVEkVLN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658832764564,"user_tz":-330,"elapsed":17,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"3c9cfcb2-75ff-426e-8210-d193d25f8a76"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.25"]},"metadata":{},"execution_count":27}],"source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, y_test_predRounded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIA9wlFu1Szx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658832764564,"user_tz":-330,"elapsed":15,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"d971caa8-f2f0-4a6a-f4d7-b874c4612c48"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.25"]},"metadata":{},"execution_count":28}],"source":["from sklearn.metrics import f1_score\n","f1_score(y_test, y_test_predRounded, average='micro')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mffkJQCU2FXn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658832764564,"user_tz":-330,"elapsed":14,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"614a7ce8-50be-4ef9-d236-73055fe8ed63"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.25"]},"metadata":{},"execution_count":29}],"source":["from sklearn.metrics import recall_score\n","recall_score(y_test, y_test_predRounded, average='micro')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9MEUm8rPC9bw","executionInfo":{"status":"ok","timestamp":1658832764564,"user_tz":-330,"elapsed":13,"user":{"displayName":"Janith Silva","userId":"15329634388737303866"}},"outputId":"e2134282-7ea7-4114-bf44-590d7c0e1154"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.25"]},"metadata":{},"execution_count":30}],"source":["from sklearn.metrics import precision_score\n","precision_score(y_test,  y_test_predRounded, average='micro')"]}],"metadata":{"colab":{"provenance":[{"file_id":"1C29XcV-ykBUe9MVmlwPBBbh4IGtA-p9y","timestamp":1634686939845}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}